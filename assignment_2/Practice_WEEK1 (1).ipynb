{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. python for beginners Automate the Boring Stuff with Python https://automatetheboringstuff.com/\n",
    "2. natural language toolkit https://www.nltk.org/\n",
    "3. pandas https://pandas.pydata.org/docs/index.html\n",
    "4. regular expressions \n",
    "5. for russian https://pymorphy2.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I was lucky — I found what I loved to do early in life. \\\n",
    "Woz and I started Apple in my parents’ garage when I was 20.\\\n",
    "We worked hard, and in 10 years Apple had grown from just the two of us in a \\\n",
    "garage into a $2 billion company with over 4,000 employees. We had just released \\\n",
    "our finest creation — the Macintosh — a year earlier, and I had just turned 30.\\\n",
    "And then I got fired. How can you get fired from a company you started? \\\n",
    "Well, as Apple grew we hired someone who I thought was very talented to \\\n",
    "run the company with me, and for the first year or so things went well.\\\n",
    "But then our visions of the future began to diverge and eventually we had a falling out.\\\n",
    "When we did, our Board of Directors sided with him. So at 30 I was out. '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenizing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So at 30 I was out.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tokenizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'was', 'lucky', '—', 'I', 'found', 'what', 'I', 'loved', 'to', 'do', 'early', 'in', 'life', '.', 'Woz', 'and', 'I', 'started', 'Apple', 'in', 'my', 'parents', '’', 'garage', 'when', 'I', 'was', '20.We', 'worked', 'hard', ',', 'and', 'in', '10', 'years', 'Apple', 'had', 'grown', 'from', 'just', 'the', 'two', 'of', 'us', 'in', 'a', 'garage', 'into', 'a', '$', '2', 'billion', 'company', 'with', 'over', '4,000', 'employees', '.', 'We', 'had', 'just', 'released', 'our', 'finest', 'creation', '—', 'the', 'Macintosh', '—', 'a', 'year', 'earlier', ',', 'and', 'I', 'had', 'just', 'turned', '30.And', 'then', 'I', 'got', 'fired', '.', 'How', 'can', 'you', 'get', 'fired', 'from', 'a', 'company', 'you', 'started', '?', 'Well', ',', 'as', 'Apple', 'grew', 'we', 'hired', 'someone', 'who', 'I', 'thought', 'was', 'very', 'talented', 'to', 'run', 'the', 'company', 'with', 'me', ',', 'and', 'for', 'the', 'first', 'year', 'or', 'so', 'things', 'went', 'well.But', 'then', 'our', 'visions', 'of', 'the', 'future', 'began', 'to', 'diverge', 'and', 'eventually', 'we', 'had', 'a', 'falling', 'out.When', 'we', 'did', ',', 'our', 'Board', 'of', 'Directors', 'sided', 'with', 'him', '.', 'So', 'at', '30', 'I', 'was', 'out', '.']  \n"
     ]
    }
   ],
   "source": [
    "print(tokens, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_rus = SnowballStemmer(language='russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'крас'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_rus.stem('красые')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_stemmed = [stemming.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'wa', 'lucki', '—', 'I', 'found', 'what', 'I', 'love', 'to', 'do', 'earli', 'in', 'life', '.', 'woz', 'and', 'I', 'start', 'appl', 'in', 'my', 'parent', '’', 'garag', 'when', 'I', 'wa', '20.we', 'work', 'hard', ',', 'and', 'in', '10', 'year', 'appl', 'had', 'grown', 'from', 'just', 'the', 'two', 'of', 'us', 'in', 'a', 'garag', 'into', 'a', '$', '2', 'billion', 'compani', 'with', 'over', '4,000', 'employe', '.', 'We', 'had', 'just', 'releas', 'our', 'finest', 'creation', '—', 'the', 'macintosh', '—', 'a', 'year', 'earlier', ',', 'and', 'I', 'had', 'just', 'turn', '30.and', 'then', 'I', 'got', 'fire', '.', 'how', 'can', 'you', 'get', 'fire', 'from', 'a', 'compani', 'you', 'start', '?', 'well', ',', 'as', 'appl', 'grew', 'we', 'hire', 'someon', 'who', 'I', 'thought', 'wa', 'veri', 'talent', 'to', 'run', 'the', 'compani', 'with', 'me', ',', 'and', 'for', 'the', 'first', 'year', 'or', 'so', 'thing', 'went', 'well.but', 'then', 'our', 'vision', 'of', 'the', 'futur', 'began', 'to', 'diverg', 'and', 'eventu', 'we', 'had', 'a', 'fall', 'out.when', 'we', 'did', ',', 'our', 'board', 'of', 'director', 'side', 'with', 'him', '.', 'So', 'at', '30', 'I', 'wa', 'out', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmat_tokens = [wnl.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'wa', 'lucky', '—', 'I', 'found', 'what', 'I', 'loved', 'to', 'do', 'early', 'in', 'life', '.', 'Woz', 'and', 'I', 'started', 'Apple', 'in', 'my', 'parent', '’', 'garage', 'when', 'I', 'wa', '20.We', 'worked', 'hard', ',', 'and', 'in', '10', 'year', 'Apple', 'had', 'grown', 'from', 'just', 'the', 'two', 'of', 'u', 'in', 'a', 'garage', 'into', 'a', '$', '2', 'billion', 'company', 'with', 'over', '4,000', 'employee', '.', 'We', 'had', 'just', 'released', 'our', 'finest', 'creation', '—', 'the', 'Macintosh', '—', 'a', 'year', 'earlier', ',', 'and', 'I', 'had', 'just', 'turned', '30.And', 'then', 'I', 'got', 'fired', '.', 'How', 'can', 'you', 'get', 'fired', 'from', 'a', 'company', 'you', 'started', '?', 'Well', ',', 'a', 'Apple', 'grew', 'we', 'hired', 'someone', 'who', 'I', 'thought', 'wa', 'very', 'talented', 'to', 'run', 'the', 'company', 'with', 'me', ',', 'and', 'for', 'the', 'first', 'year', 'or', 'so', 'thing', 'went', 'well.But', 'then', 'our', 'vision', 'of', 'the', 'future', 'began', 'to', 'diverge', 'and', 'eventually', 'we', 'had', 'a', 'falling', 'out.When', 'we', 'did', ',', 'our', 'Board', 'of', 'Directors', 'sided', 'with', 'him', '.', 'So', 'at', '30', 'I', 'wa', 'out', '.']  \n"
     ]
    }
   ],
   "source": [
    "print(lemmat_tokens, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {'n': 'NN', 'VBD': 'v', 'VB':'v' }\n",
    "def lemmatize_word(token):\n",
    "    word_pos = nltk.pos_tag([token])\n",
    "    print(word_pos)\n",
    "    if word_pos[0][1] in pos_dict:\n",
    "        return wnl.lemmatize(token, pos=pos_dict[word_pos[0][1]])\n",
    "    else:\n",
    "        return wnl.lemmatize(token)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet._morphy('was', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP')]\n",
      "[('was', 'VBD')]\n",
      "[('lucky', 'JJ')]\n",
      "[('—', 'NN')]\n",
      "[('I', 'PRP')]\n",
      "[('found', 'NN')]\n",
      "[('what', 'WP')]\n",
      "[('I', 'PRP')]\n",
      "[('loved', 'VBN')]\n",
      "[('to', 'TO')]\n",
      "[('do', 'VB')]\n",
      "[('early', 'RB')]\n",
      "[('in', 'IN')]\n",
      "[('life', 'NN')]\n",
      "[('.', '.')]\n",
      "[('Woz', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('I', 'PRP')]\n",
      "[('started', 'VBN')]\n",
      "[('Apple', 'NNP')]\n",
      "[('in', 'IN')]\n",
      "[('my', 'PRP$')]\n",
      "[('parents', 'NNS')]\n",
      "[('’', 'NN')]\n",
      "[('garage', 'NN')]\n",
      "[('when', 'WRB')]\n",
      "[('I', 'PRP')]\n",
      "[('was', 'VBD')]\n",
      "[('20.We', 'CD')]\n",
      "[('worked', 'VBN')]\n",
      "[('hard', 'JJ')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('in', 'IN')]\n",
      "[('10', 'CD')]\n",
      "[('years', 'NNS')]\n",
      "[('Apple', 'NNP')]\n",
      "[('had', 'VBD')]\n",
      "[('grown', 'NN')]\n",
      "[('from', 'IN')]\n",
      "[('just', 'RB')]\n",
      "[('the', 'DT')]\n",
      "[('two', 'CD')]\n",
      "[('of', 'IN')]\n",
      "[('us', 'PRP')]\n",
      "[('in', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('garage', 'NN')]\n",
      "[('into', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('$', '$')]\n",
      "[('2', 'CD')]\n",
      "[('billion', 'CD')]\n",
      "[('company', 'NN')]\n",
      "[('with', 'IN')]\n",
      "[('over', 'IN')]\n",
      "[('4,000', 'CD')]\n",
      "[('employees', 'NNS')]\n",
      "[('.', '.')]\n",
      "[('We', 'PRP')]\n",
      "[('had', 'VBD')]\n",
      "[('just', 'RB')]\n",
      "[('released', 'VBN')]\n",
      "[('our', 'PRP$')]\n",
      "[('finest', 'JJS')]\n",
      "[('creation', 'NN')]\n",
      "[('—', 'NN')]\n",
      "[('the', 'DT')]\n",
      "[('Macintosh', 'NNP')]\n",
      "[('—', 'NN')]\n",
      "[('a', 'DT')]\n",
      "[('year', 'NN')]\n",
      "[('earlier', 'RBR')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('I', 'PRP')]\n",
      "[('had', 'VBD')]\n",
      "[('just', 'RB')]\n",
      "[('turned', 'VBD')]\n",
      "[('30.And', 'CD')]\n",
      "[('then', 'RB')]\n",
      "[('I', 'PRP')]\n",
      "[('got', 'VBD')]\n",
      "[('fired', 'VBN')]\n",
      "[('.', '.')]\n",
      "[('How', 'WRB')]\n",
      "[('can', 'MD')]\n",
      "[('you', 'PRP')]\n",
      "[('get', 'VB')]\n",
      "[('fired', 'VBN')]\n",
      "[('from', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('company', 'NN')]\n",
      "[('you', 'PRP')]\n",
      "[('started', 'VBN')]\n",
      "[('?', '.')]\n",
      "[('Well', 'RB')]\n",
      "[(',', ',')]\n",
      "[('as', 'IN')]\n",
      "[('Apple', 'NNP')]\n",
      "[('grew', 'VBD')]\n",
      "[('we', 'PRP')]\n",
      "[('hired', 'VBN')]\n",
      "[('someone', 'NN')]\n",
      "[('who', 'WP')]\n",
      "[('I', 'PRP')]\n",
      "[('thought', 'NN')]\n",
      "[('was', 'VBD')]\n",
      "[('very', 'RB')]\n",
      "[('talented', 'VBN')]\n",
      "[('to', 'TO')]\n",
      "[('run', 'VB')]\n",
      "[('the', 'DT')]\n",
      "[('company', 'NN')]\n",
      "[('with', 'IN')]\n",
      "[('me', 'PRP')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('for', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('first', 'RB')]\n",
      "[('year', 'NN')]\n",
      "[('or', 'CC')]\n",
      "[('so', 'RB')]\n",
      "[('things', 'NNS')]\n",
      "[('went', 'VBD')]\n",
      "[('well.But', 'NN')]\n",
      "[('then', 'RB')]\n",
      "[('our', 'PRP$')]\n",
      "[('visions', 'NNS')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('future', 'NN')]\n",
      "[('began', 'VBD')]\n",
      "[('to', 'TO')]\n",
      "[('diverge', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('eventually', 'RB')]\n",
      "[('we', 'PRP')]\n",
      "[('had', 'VBD')]\n",
      "[('a', 'DT')]\n",
      "[('falling', 'VBG')]\n",
      "[('out.When', 'NN')]\n",
      "[('we', 'PRP')]\n",
      "[('did', 'VBD')]\n",
      "[(',', ',')]\n",
      "[('our', 'PRP$')]\n",
      "[('Board', 'NNP')]\n",
      "[('of', 'IN')]\n",
      "[('Directors', 'NNS')]\n",
      "[('sided', 'VBD')]\n",
      "[('with', 'IN')]\n",
      "[('him', 'PRP')]\n",
      "[('.', '.')]\n",
      "[('So', 'RB')]\n",
      "[('at', 'IN')]\n",
      "[('30', 'CD')]\n",
      "[('I', 'PRP')]\n",
      "[('was', 'VBD')]\n",
      "[('out', 'IN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "lemmatized_words = [lemmatize_word(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://regex101.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ainur/Desktop/NLP/WEEK1/archive/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises. Deadline 14.02.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download IMDB film review file dataset from the classroom \n",
    "2. Read this file by pandas dataframe (preferably) \n",
    "3. Analyse and do text preprocessing:\\\n",
    "    3.1 Tokenization \\\n",
    "    3.2 Lemmatization \\\n",
    "    3.3 Remove stopwords \\\n",
    "    3.4 Remove punctuations\\\n",
    "    3.5 By using regular expressions find:\n",
    "        1. Any text in angle braces <> and remove them\n",
    "        2. Find symbols (not character and numbers) in text and delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
